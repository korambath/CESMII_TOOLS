{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b7b6b78-6027-4881-9248-e3fe976651a3",
   "metadata": {},
   "source": [
    "https://github.com/openai/openai-agents-python/tree/main/examples\n",
    "\n",
    "\n",
    "https://openai.github.io/openai-agents-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f8f9c3-6614-4bbd-8708-7c2f8f3de8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "from IPython.display import display, Markdown\n",
    "from agents import Agent, Runner, trace\n",
    "import asyncio\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "    \n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "    \n",
    "print(f\"OpenAI API Key set: {'Yes' if os.environ.get('OPENAI_API_KEY') and os.environ['OPENAI_API_KEY'] != 'YOUR_OPENAI_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "print(f\"Google API Key set: {'Yes' if os.environ.get('GOOGLE_API_KEY') and os.environ['GOOGLE_API_KEY'] != 'YOUR_GOOGLE_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "# disable tracing\n",
    "\n",
    "OPENAI_AGENTS_DISABLE_TRACING=1\n",
    "from agents import Agent, Runner, set_tracing_disabled\n",
    "# Explicitly disable tracing\n",
    "set_tracing_disabled(disabled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e4a3d-1667-4e5c-9f69-75be564291dc",
   "metadata": {},
   "source": [
    "### Hello world example\n",
    "\n",
    "\n",
    "Run a workflow starting at the given agent. The agent will run in a loop until a final output is generated. The loop runs like so: 1. The agent is invoked with the given input. 2. If there is a final output (i.e. the agent produces something of type agent.output_type, the loop terminates. 3. If there's a handoff, we run the loop again, with the new agent. 4. Else, we run tool calls (if any), and re-run the loop.\n",
    "\n",
    "\n",
    "In two cases, the agent may raise an exception: 1. If the max_turns is exceeded, a MaxTurnsExceeded exception is raised. 2. If a guardrail tripwire is triggered, a GuardrailTripwireTriggered exception is raised.\n",
    "\n",
    "Note that only the first agent's input guardrails are run.\n",
    "\n",
    "\n",
    "```\n",
    "run(\n",
    "    starting_agent: Agent[TContext],\n",
    "    input: str | list[TResponseInputItem],\n",
    "    *,\n",
    "    context: TContext | None = None,\n",
    "    max_turns: int = DEFAULT_MAX_TURNS,\n",
    "    hooks: RunHooks[TContext] | None = None,\n",
    "    run_config: RunConfig | None = None,\n",
    "    previous_response_id: str | None = None,\n",
    ") -> RunResult\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1389e541-3fbd-4f84-9655-760986904a77",
   "metadata": {},
   "source": [
    "\n",
    "You can run agents via the Runner class. You have 3 options:\n",
    "\n",
    "    Runner.run(), which runs async and returns a RunResult.\n",
    "    Runner.run_sync(), which is a sync method and just runs .run() under the hood.\n",
    "    Runner.run_streamed(), which runs async and returns a RunResultStreaming. It calls the LLM in streaming mode, and streams those events to you as they are received.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f335790b-c261-4586-8e58-67d10600d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
    "\n",
    "#result = Runner.run_sync(agent, \"Write a haiku about recursion in programming.\")\n",
    "#print(result.final_output)\n",
    "\n",
    "async def main():\n",
    "    result = await Runner.run(agent, \"What is the capital of France?\")\n",
    "    print(result.final_output)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #asyncio.run(main())\n",
    "    await main()\n",
    "\n",
    "# Code within the code,\n",
    "# Functions calling themselves,\n",
    "# Infinite loop's dance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad4ab9e-c0bd-4eff-9412-7c5f653ab95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    agent = Agent(name=\"Assistant\", instructions=\"Reply very concisely.\")\n",
    "    thread_id = 1234\n",
    "\n",
    "    with trace(workflow_name=\"Conversation\", group_id=thread_id):\n",
    "        # First turn\n",
    "        result = await Runner.run(agent, \"What city is the Golden Gate Bridge in?\")\n",
    "        print(result.final_output)\n",
    "        # San Francisco\n",
    "\n",
    "        # Second turn\n",
    "        new_input = result.to_input_list() + [{\"role\": \"user\", \"content\": \"What state is it in?\"}]\n",
    "        result = await Runner.run(agent, new_input)\n",
    "        print(result.final_output)\n",
    "        # California\n",
    "if __name__ == \"__main__\":\n",
    "    #asyncio.run(main())\n",
    "    await main()\n",
    "    \n",
    "#result = await Runner.run(agent, \"What is the weather in Los Angeles?\")\n",
    "#print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a8935-26cf-4941-af7b-d8b9b79cce5f",
   "metadata": {},
   "source": [
    "#### First agent\n",
    "\n",
    "- https://github.com/openai/openai-agents-python/tree/main/examples\n",
    "- https://openai.github.io/openai-agents-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d0a6b9-4314-48ef-8c35-6b30f0328724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent = Agent(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "\n",
    "result = Runner.run_streamed(agent, input=\"what is square root of 4.\")\n",
    "async for event in result.stream_events():\n",
    "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "        print(event.data.delta, end=\"\", flush=True)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ebed0-214e-4d44-9f0c-d51891f82532",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e99f09-9c45-4cd2-9efa-eed74e5d0010",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    #agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
    "    agent = Agent(\n",
    "       name=\"Math Tutor\",\n",
    "       instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
    "       model=\"gpt-4o\"\n",
    "    )\n",
    "    result = await Runner.run(agent, \"what is square root of 4\")\n",
    "    print(result.final_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #asyncio.run(main())\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da99693-a6e6-480a-9c39-c369b17faf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "from agents import Agent, ItemHelpers, Runner, function_tool\n",
    "\n",
    "result = Runner.run_streamed(\n",
    "    agent,\n",
    "    input=\"What is square root of 4.\",\n",
    ")\n",
    "print(\"=== Run starting ===\")\n",
    "\n",
    "async for event in result.stream_events():\n",
    "    # Ignore the raw responses \n",
    "    if event.type == \"raw_response_event\":\n",
    "        continue\n",
    "    # print agent updates\n",
    "    elif event.type == \"agent_updated_stream_event\":\n",
    "        print(f\"Agent updated: {event.new_agent.name}\")\n",
    "        continue\n",
    "    # print generated items\n",
    "    elif event.type == \"run_item_stream_event\":\n",
    "        if event.item.type == \"tool_call_item\":\n",
    "            print(\"-- Tool was called\")\n",
    "        elif event.item.type == \"tool_call_output_item\":\n",
    "            print(f\"-- Tool output: {event.item.output}\")\n",
    "        elif event.item.type == \"message_output_item\":\n",
    "            print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
    "        else:\n",
    "            pass  # Ignore other event types\n",
    "\n",
    "print(\"=== Run complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90111104-21d9-4ac8-8d0f-b386407d9c23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k, v in result.__dict__.items():\n",
    "  print(f\"Key = {k}: Value = {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1bdbcd-bf52-46c4-8801-f56f12823770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import ModelSettings\n",
    "\n",
    "\n",
    "advanced_agent = Agent(\n",
    "   name=\"Advanced Assistant\",\n",
    "   instructions=\"\"\"You are a an advnanced assistant who knows about engineering facts. Give \n",
    "   accurate information. If you don't know something, clearly state that.\n",
    "   Take a pass if you don't know. \"\"\",\n",
    "   model=\"gpt-4o\",\n",
    "   model_settings=ModelSettings(\n",
    "       temperature=0.3,  # Lower for more deterministic outputs (0.0-2.0)\n",
    "       max_tokens=1024,  # Maximum length of response\n",
    "   ),\n",
    "   tools=[]  # We'll cover tools in a later section\n",
    ")\n",
    "result = await Runner.run(agent, \"Tell me about quantum computers.\")\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355ed5ef-4b7e-44bd-a086-2caf9cd91c95",
   "metadata": {},
   "source": [
    "### Streaming Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f65576-60d9-401f-b93b-03da8d128c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from agents import Agent, Runner\n",
    "\n",
    "async def main():\n",
    "    agent = Agent(\n",
    "        name=\"Joker\",\n",
    "        instructions=\"You are a helpful assistant.\",\n",
    "    )\n",
    "\n",
    "    result = Runner.run_streamed(agent, input=\"Please tell me 5 jokes.\")\n",
    "    async for event in result.stream_events():\n",
    "        if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "            print(event.data.delta, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #asyncio.run(main())\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a169ca50-6be1-4683-831a-21a7e6719491",
   "metadata": {},
   "source": [
    "### Handoff Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d82ddb-d963-4860-8f72-921b83e8ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner\n",
    "import asyncio\n",
    "\n",
    "french_agent = Agent(\n",
    "    name=\"french agent\",\n",
    "    instructions=\"You only speak French.\",\n",
    ")\n",
    "\n",
    "italian_agent = Agent(\n",
    "    name=\"italian agent\",\n",
    "    instructions=\"You only speak Italian.\",\n",
    ")\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"Spanish agent\",\n",
    "    instructions=\"You only speak Spanish.\",\n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"English agent\",\n",
    "    instructions=\"You only speak English\",\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
    "    handoffs=[spanish_agent, english_agent, french_agent, italian_agent],\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    input=\"Hola, ¿cómo estás?\"\n",
    "    result = await Runner.run(triage_agent, input=input)\n",
    "    print(f\" Input = {input}, Output = {result.final_output}\")\n",
    "    input=\"Hello How are you?\"\n",
    "    result = await Runner.run(triage_agent, input=input)\n",
    "    print(f\" Input = {input}, Output = {result.final_output}\")\n",
    "    input=\"bonjour comment allez-vous?\"\n",
    "    result = await Runner.run(triage_agent, input=input )\n",
    "    print(f\" Input = {input}, Output = {result.final_output}\")\n",
    "    input=\"Salve, come stai?\"\n",
    "    result = await Runner.run(triage_agent, input=input)\n",
    "    print(f\" Input = {input}, Output = {result.final_output}\")\n",
    "    #print(result.final_output)\n",
    "    # ¡Hola! Estoy bien, gracias por preguntar. ¿Y tú, cómo estás?\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #asyncio.run(main())\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a8d77-6a68-40bf-b86c-3b36d32f4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent\n",
    "\n",
    "history_tutor_agent = Agent(\n",
    "    name=\"History Tutor\",\n",
    "    handoff_description=\"Specialist agent for historical questions\",\n",
    "    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\",\n",
    ")\n",
    "\n",
    "math_tutor_agent = Agent(\n",
    "    name=\"Math Tutor\",\n",
    "    handoff_description=\"Specialist agent for math questions\",\n",
    "    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11610301-fa5d-488b-8f39-84d1e6745564",
   "metadata": {},
   "outputs": [],
   "source": [
    "triage_agent = Agent(\n",
    "    name=\"Triage Agent\",\n",
    "    instructions=\"You determine which agent to use based on the user's homework question\",\n",
    "    handoffs=[history_tutor_agent, math_tutor_agent]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e31f7-6959-4494-a8bb-3417bd60c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    result = await Runner.run(triage_agent, input=\"Where is 2028 olympics?\")\n",
    "    print(result.final_output)\n",
    "    result = await Runner.run(triage_agent, input=\"What is 0 + 1?\")\n",
    "    print(result.final_output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #asyncio.run(main())\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafb38f6-477d-4fab-a46b-4b1fcfa179ee",
   "metadata": {},
   "source": [
    "### Run the agent orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53049e8c-f862-4434-a407-23b18eed7ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner\n",
    "\n",
    "async def main():\n",
    "    result = await Runner.run(triage_agent, \"What is the capital of France?\")\n",
    "    print(result.final_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #asyncio.run(main())\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ef876-80eb-41f7-a65b-e7314070ef03",
   "metadata": {},
   "source": [
    "### Function Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e70ed5-3b7e-427e-8682-596b353d1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from agents import Agent, Runner, function_tool\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Hello world\",\n",
    "    instructions=\"You are a helpful agent.\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    result = await Runner.run(agent, input=\"What's the weather in Tokyo?\")\n",
    "    print(result.final_output)\n",
    "    # The weather in Tokyo is sunny.\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #asyncio.run(main())\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d511ca3-81a2-4c94-8a70-f5b5d969a988",
   "metadata": {},
   "source": [
    "### Add a guardrail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d84a6f-a805-4dfd-81ec-195a78ee90fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import GuardrailFunctionOutput, Agent, Runner\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class HomeworkOutput(BaseModel):\n",
    "    is_homework: bool\n",
    "    reasoning: str\n",
    "\n",
    "guardrail_agent = Agent(\n",
    "    name=\"Guardrail check\",\n",
    "    instructions=\"Check if the user is asking about homework.\",\n",
    "    output_type=HomeworkOutput,\n",
    ")\n",
    "\n",
    "async def homework_guardrail(ctx, agent, input_data):\n",
    "    result = await Runner.run(guardrail_agent, input_data, context=ctx.context)\n",
    "    final_output = result.final_output_as(HomeworkOutput)\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=final_output,\n",
    "        tripwire_triggered=not final_output.is_homework,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d339410-aa3b-4714-86f6-b7fbdcde085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    input=\"who was the first president of the united states?\"\n",
    "    result = await Runner.run(guardrail_agent, input)\n",
    "    print(f\" Input = {input}, Output = {result.final_output}\")\n",
    "    input = \"what is 1 + 1\"\n",
    "    result = await Runner.run(triage_agent, input )\n",
    "    print(f\" Input = {input}, Output = {result.final_output}\")\n",
    "    input = \"what is life?\"\n",
    "    result = await Runner.run(triage_agent, input )\n",
    "    print(f\" Input = {input}, Output = {result.final_output}\")\n",
    "    input = \"who was the first president of University of California system?\"\n",
    "    result = await Runner.run(guardrail_agent, input)\n",
    "    print(f\" Input = {input}, Output = {result.final_output}\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #asyncio.run(main())\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a28531-f994-4cdc-bb4b-7e1b72947881",
   "metadata": {},
   "source": [
    "### Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407040a1-ebae-4db9-896e-ecaf2cdd3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, InputGuardrail, GuardrailFunctionOutput, Runner\n",
    "from pydantic import BaseModel\n",
    "import asyncio\n",
    "\n",
    "class HomeworkOutput(BaseModel):\n",
    "    is_homework: bool\n",
    "    reasoning: str\n",
    "\n",
    "guardrail_agent = Agent(\n",
    "    name=\"Guardrail check\",\n",
    "    instructions=\"Check if the user is asking about homework.\",\n",
    "    output_type=HomeworkOutput,\n",
    ")\n",
    "\n",
    "math_tutor_agent = Agent(\n",
    "    name=\"Math Tutor\",\n",
    "    handoff_description=\"Specialist agent for math questions\",\n",
    "    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
    ")\n",
    "\n",
    "history_tutor_agent = Agent(\n",
    "    name=\"History Tutor\",\n",
    "    handoff_description=\"Specialist agent for historical questions\",\n",
    "    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\",\n",
    ")\n",
    "\n",
    "\n",
    "async def homework_guardrail(ctx, agent, input_data):\n",
    "    result = await Runner.run(guardrail_agent, input_data, context=ctx.context)\n",
    "    final_output = result.final_output_as(HomeworkOutput)\n",
    "    print(f\"Guardrail check is {final_output} \\n\")\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=final_output,\n",
    "        tripwire_triggered=not final_output.is_homework,\n",
    "    )\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage Agent\",\n",
    "    instructions=\"You determine which agent to use based on the user's homework question\",\n",
    "    handoffs=[history_tutor_agent, math_tutor_agent],\n",
    "    input_guardrails=[\n",
    "        InputGuardrail(guardrail_function=homework_guardrail),\n",
    "    ],\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    result = await Runner.run(triage_agent, \"who was the first president of the united states?\")\n",
    "    print(result.final_output)\n",
    "\n",
    "\n",
    "    # #result = await Runner.run(triage_agent, \"what is life\")\n",
    "    # result = await Runner.run(triage_agent, \"who was the first president of University of California system?\")\n",
    "    # print(result.final_output)\n",
    "    # #print(result.final_output)\n",
    "    result = await Runner.run(triage_agent, \"what is 1 + 1\")\n",
    "    print(result.final_output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #asyncio.run(main())\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce5dd38-b9e3-4b2c-aafd-205022019ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from agents import (\n",
    "    Agent,\n",
    "    GuardrailFunctionOutput,\n",
    "    InputGuardrailTripwireTriggered,\n",
    "    RunContextWrapper,\n",
    "    Runner,\n",
    "    TResponseInputItem,\n",
    "    input_guardrail,\n",
    ")\n",
    "\n",
    "class MathHomeworkOutput(BaseModel):\n",
    "    is_math_homework: bool\n",
    "    reasoning: str\n",
    "\n",
    "guardrail_agent = Agent( \n",
    "    name=\"Guardrail check\",\n",
    "    instructions=\"Check if the user is asking you to do their math homework.\",\n",
    "    output_type=MathHomeworkOutput,\n",
    ")\n",
    "\n",
    "\n",
    "@input_guardrail\n",
    "async def math_guardrail( \n",
    "    ctx: RunContextWrapper[None], agent: Agent, input: str | list[TResponseInputItem]\n",
    ") -> GuardrailFunctionOutput:\n",
    "    result = await Runner.run(guardrail_agent, input, context=ctx.context)\n",
    "\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=result.final_output, \n",
    "        tripwire_triggered=result.final_output.is_math_homework,\n",
    "    )\n",
    "\n",
    "\n",
    "agent = Agent(  \n",
    "    name=\"Customer support agent\",\n",
    "    instructions=\"You are a customer support agent. You help customers with their questions.\",\n",
    "    input_guardrails=[math_guardrail],\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    # This should trip the guardrail\n",
    "    try:\n",
    "        await Runner.run(agent, \"Hello, can you help me solve for x: 2x + 3 = 11?\")\n",
    "        print(\"Guardrail didn't trip - this is unexpected\")\n",
    "\n",
    "    except InputGuardrailTripwireTriggered:\n",
    "        print(\"Math homework guardrail tripped\")\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f6a255-2bd8-4c88-aa25-2481b055f871",
   "metadata": {},
   "source": [
    "### output guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b065094-f289-412b-b58c-d8cc75c4c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from agents import (\n",
    "    Agent,\n",
    "    GuardrailFunctionOutput,\n",
    "    OutputGuardrailTripwireTriggered,\n",
    "    RunContextWrapper,\n",
    "    Runner,\n",
    "    output_guardrail,\n",
    ")\n",
    "class MessageOutput(BaseModel): \n",
    "    response: str\n",
    "\n",
    "class MathOutput(BaseModel): \n",
    "    reasoning: str\n",
    "    is_math: bool\n",
    "\n",
    "guardrail_agent = Agent(\n",
    "    name=\"Guardrail check\",\n",
    "    instructions=\"Check if the output includes any math.\",\n",
    "    output_type=MathOutput,\n",
    ")\n",
    "\n",
    "@output_guardrail\n",
    "async def math_guardrail(  \n",
    "    ctx: RunContextWrapper, agent: Agent, output: MessageOutput\n",
    ") -> GuardrailFunctionOutput:\n",
    "    result = await Runner.run(guardrail_agent, output.response, context=ctx.context)\n",
    "\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=result.final_output,\n",
    "        tripwire_triggered=result.final_output.is_math,\n",
    "    )\n",
    "\n",
    "agent = Agent( \n",
    "    name=\"Customer support agent\",\n",
    "    instructions=\"You are a customer support agent. You help customers with their questions.\",\n",
    "    output_guardrails=[math_guardrail],\n",
    "    output_type=MessageOutput,\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    # This should trip the guardrail\n",
    "    try:\n",
    "        await Runner.run(agent, \"Hello, can you help me solve for x: 2x + 3 = 11?\")\n",
    "        print(\"Guardrail didn't trip - this is unexpected\")\n",
    "\n",
    "    except OutputGuardrailTripwireTriggered:\n",
    "        print(\"Math output guardrail tripped\")\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb51094-09f1-4db1-955f-51688371c875",
   "metadata": {},
   "source": [
    "### event types for streamed events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac050fe-0948-4a4f-96f3-b231781fcd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"openai.agents\") # or openai.agents.tracing for the Tracing logger\n",
    "\n",
    "# To make all logs show up\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# To make info and above show up\n",
    "logger.setLevel(logging.INFO)\n",
    "# To make warning and above show up\n",
    "logger.setLevel(logging.WARNING)\n",
    "# etc\n",
    "\n",
    "# You can customize this as needed, but this will output to `stderr` by default\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8595b7-5d70-474f-ac94-d6e7727c1e56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "from agents import Agent, ItemHelpers, Runner, function_tool\n",
    "\n",
    "@function_tool\n",
    "def how_many_jokes() -> int:\n",
    "    #return random.randint(1, 10)\n",
    "    no_str = input(\"Enter number of jokes: \")\n",
    "    number = int(no_str)  # Convert the input string to an integer\n",
    "    print(f\"You asked for {number} jokes\")\n",
    "    return number\n",
    "\n",
    "\n",
    "async def main():\n",
    "    agent = Agent(\n",
    "        name=\"Joker\",\n",
    "        instructions=\"First call the `how_many_jokes` tool, then tell that many jokes.\",\n",
    "        tools=[how_many_jokes],\n",
    "    )\n",
    "\n",
    "    result = Runner.run_streamed(\n",
    "        agent,\n",
    "        input=\"Hello\",\n",
    "    )\n",
    "    print(\"=== Run starting ===\")\n",
    "\n",
    "    async for event in result.stream_events():\n",
    "        # We'll ignore the raw responses event deltas\n",
    "        if event.type == \"raw_response_event\":\n",
    "            continue\n",
    "        # When the agent updates, print that\n",
    "        elif event.type == \"agent_updated_stream_event\":\n",
    "            print(f\"Agent updated: {event.new_agent.name}\")\n",
    "            continue\n",
    "        # When items are generated, print them\n",
    "        elif event.type == \"run_item_stream_event\":\n",
    "            if event.item.type == \"tool_call_item\":\n",
    "                print(\"-- Tool was called\")\n",
    "            elif event.item.type == \"tool_call_output_item\":\n",
    "                print(f\"-- Tool output: {event.item.output}\")\n",
    "            elif event.item.type == \"message_output_item\":\n",
    "                print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
    "            else:\n",
    "                pass  # Ignore other event types\n",
    "\n",
    "    print(\"=== Run complete ===\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #asyncio.run(main())\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20f8102-0ddf-4889-a82d-9f98004df02f",
   "metadata": {},
   "source": [
    "### Agents as tools and orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd8acce-b0fb-4f3a-bba7-217e2edc0a65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from agents import Agent, Runner\n",
    "import asyncio\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"Spanish agent\",\n",
    "    instructions=\"You translate the user's message to Spanish\",\n",
    ")\n",
    "\n",
    "french_agent = Agent(\n",
    "    name=\"French agent\",\n",
    "    instructions=\"You translate the user's message to French\",\n",
    ")\n",
    "\n",
    "orchestrator_agent = Agent(\n",
    "    name=\"orchestrator_agent\",\n",
    "    instructions=(\n",
    "        \"You are a translation agent. You use the tools given to you to translate.\"\n",
    "        \"If asked for multiple translations, you call the relevant tools.\"\n",
    "    ),\n",
    "    tools=[\n",
    "        spanish_agent.as_tool(\n",
    "            tool_name=\"translate_to_spanish\",\n",
    "            tool_description=\"Translate the user's message to Spanish\",\n",
    "        ),\n",
    "        french_agent.as_tool(\n",
    "            tool_name=\"translate_to_french\",\n",
    "            tool_description=\"Translate the user's message to French\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    result = await Runner.run(orchestrator_agent, input=\"Say 'Hello, how are you?' in Spanish.\")\n",
    "    print(result.final_output)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e901be-54d7-499a-8834-3808a6d3416f",
   "metadata": {},
   "source": [
    "#### Ask your translation questions in any language including websearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbccf1-f243-479a-84f0-6c97fe014f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from agents import Agent, FileSearchTool, Runner, WebSearchTool\n",
    "from agents import Agent, ItemHelpers, MessageOutputItem, Runner, trace\n",
    "\n",
    "\"\"\"\n",
    "This example shows the agents-as-tools pattern. The frontline agent receives a user message and\n",
    "then picks which agents to call, as tools. In this case, it picks from a set of translation\n",
    "agents.\n",
    "\"\"\"\n",
    "\n",
    "malaylam_agent = Agent(\n",
    "    name=\"malaylam_agent\",\n",
    "    instructions=\"You translate the user's message to Malaylam\",\n",
    "    handoff_description=\"An english to Malaylam translator\",\n",
    ")\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"spanish_agent\",\n",
    "    instructions=\"You translate the user's message to Spanish\",\n",
    "    handoff_description=\"An english to spanish translator\",\n",
    ")\n",
    "\n",
    "french_agent = Agent(\n",
    "    name=\"french_agent\",\n",
    "    instructions=\"You translate the user's message to French\",\n",
    "    handoff_description=\"An english to french translator\",\n",
    ")\n",
    "\n",
    "italian_agent = Agent(\n",
    "    name=\"italian_agent\",\n",
    "    instructions=\"You translate the user's message to Italian\",\n",
    "    handoff_description=\"An english to italian translator\",\n",
    ")\n",
    "websearch_agent = Agent(\n",
    "    name=\"websearch_agent\",\n",
    "    instructions=f\"You are a helpful agent who can search web, respond to questions by using the search tool\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[WebSearchTool()]\n",
    ")\n",
    "\n",
    "orchestrator_agent = Agent(\n",
    "    name=\"orchestrator_agent\",\n",
    "    instructions=(\n",
    "        \"You are a translation agent. You use the tools given to you to translate.\"\n",
    "        \"If asked for multiple translations, you call the relevant tools in order.\"\n",
    "        \"You never translate on your own, you always use the provided tools.\"\n",
    "    ),\n",
    "    tools=[\n",
    "        malaylam_agent.as_tool(\n",
    "            tool_name=\"translate_to_malaylam\",\n",
    "            tool_description=\"Translate the user's message to Malayalam\",\n",
    "        ),\n",
    "        spanish_agent.as_tool(\n",
    "            tool_name=\"translate_to_spanish\",\n",
    "            tool_description=\"Translate the user's message to Spanish\",\n",
    "        ),\n",
    "        french_agent.as_tool(\n",
    "            tool_name=\"translate_to_french\",\n",
    "            tool_description=\"Translate the user's message to French\",\n",
    "        ),\n",
    "        italian_agent.as_tool(\n",
    "            tool_name=\"translate_to_italian\",\n",
    "            tool_description=\"Translate the user's message to Italian\",\n",
    "        ),\n",
    "        websearch_agent.as_tool(\n",
    "            tool_name=\"websearch_agent\",\n",
    "            tool_description=\"search web to find answers to user query\",\n",
    "        ),\n",
    "\n",
    "    ],\n",
    ")\n",
    "\n",
    "synthesizer_agent = Agent(\n",
    "    name=\"synthesizer_agent\",\n",
    "    instructions=\"You inspect translations, correct them if needed, and produce a final concatenated response.\",\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    msg = input(\"Hi! What would you like translated, and to which languages? \")\n",
    "\n",
    "    # Run the entire orchestration in a single trace\n",
    "    with trace(\"Orchestrator evaluator\"):\n",
    "        orchestrator_result = await Runner.run(orchestrator_agent, msg, max_turns=5,)\n",
    "        for item in orchestrator_result.new_items:\n",
    "            if hasattr(item, 'agent'):\n",
    "               print(f\" Agent: {item.agent.name}\")\n",
    "            if isinstance(item, MessageOutputItem):\n",
    "                text = ItemHelpers.text_message_output(item)\n",
    "                if text:\n",
    "                    print(f\"  - Translation step: {text}\")\n",
    "\n",
    "        synthesizer_result = await Runner.run(\n",
    "            synthesizer_agent, orchestrator_result.to_input_list()\n",
    "        )\n",
    "\n",
    "    print(f\"\\n\\nFinal response:\\n{synthesizer_result.final_output}\")\n",
    "    \n",
    "\n",
    "# async def main():\n",
    "#     result = await Runner.run(orchestrator_agent, input=\"Say 'Hello, how are you?' in Spanish.\")\n",
    "#     print(result.final_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #asyncio.run(main())\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb759cf3-01e0-4d2d-b451-9ec19f355152",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "951db5fc-6d59-411c-9bf8-222756369fa8",
   "metadata": {},
   "source": [
    "### Mixing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f7048-0815-4b75-9455-acb0b11d91ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791954d4-82c5-4d6d-8f11-1e74bff93b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n",
    "import asyncio\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"Spanish agent\",\n",
    "    instructions=\"You only speak Spanish.\",\n",
    "    model=\"o3-mini\", \n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"English agent\",\n",
    "    instructions=\"You only speak English\",\n",
    "    model=OpenAIChatCompletionsModel( \n",
    "        model=\"gpt-4o\",\n",
    "        openai_client=AsyncOpenAI()\n",
    "    ),\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
    "    handoffs=[spanish_agent, english_agent],\n",
    "    #handoffs=[english_agent],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    result = await Runner.run(triage_agent, input=\"Hola, ¿cómo estás?\")\n",
    "    print(result.final_output)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f7ccc-7dc6-46aa-ab9d-670d0f5ce4c0",
   "metadata": {},
   "source": [
    "### Other vendor agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e0d907-15c9-4f5d-ab9d-9b40d27bac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#claude_agent = Agent(model=\"litellm/anthropic/claude-3-5-sonnet-20240620\", ...)\n",
    "#gemini_agent = Agent(model=\"litellm/gemini/gemini-2.5-flash-preview-04-17\", ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d16cbe0-6811-4060-a5d5-e4bce50670b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "import os\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"False\"\n",
    "os.environ['GEMINI_API_KEY'] = GOOGLE_API_KEY\n",
    "response = completion(\n",
    "    model=\"gemini/gemini-2.0-flash\", \n",
    "    #messages=[{\"role\": \"user\", \"content\": \"write code for saying hi from LiteLLM\"}]\n",
    "    messages=[{\"role\": \"user\", \"content\": \"who wrote first hello world?\"}]\n",
    ")\n",
    "response.choices[0].message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb6465-1094-41fb-9429-e1c78c07e6f9",
   "metadata": {},
   "source": [
    "### Websearch Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2e06ed-37b0-45ee-923a-25bd41de08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, FileSearchTool, Runner, WebSearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca771e0-4cb4-4d7e-b2ff-f31dae1ee6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "websearch_agent = Agent(name=\"websearch_agent Assistant\",\n",
    "              instructions=f\"You are a helpful agent, respond to questions by using the search tool\",\n",
    "              model=\"gpt-4o\",\n",
    "              tools=[WebSearchTool()]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2c7cad-53f7-4314-976e-2cca8f448977",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await Runner.run(websearch_agent, \"who is the chancellor of university of california, Los Angeles?\")\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55051dc9-4003-484b-9975-324dce67f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.new_items[1].raw_item.content[0].annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8337e9ac-b7cf-4aef-94e9-2d64d2a78308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
